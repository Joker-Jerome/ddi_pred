{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smiles2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rdkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ee448a5af822>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrdkit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAllChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalMaxPooling2D, BatchNormalization\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    " \n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "print(\"RDKit: %s\"%rdkit.__version__)\n",
    "print(\"Keras: %s\"%keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r'../data/IGC50.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smiles = np.array(list(data[\"smiles\"][data[\"split\"]==1]))\n",
    "X_test_smiles = np.array(list(data[\"smiles\"][data[\"split\"]==0]))\n",
    "print(X_train_smiles.shape)\n",
    "print(X_test_smiles.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay = \"Activity\"  \n",
    "Y_train = data[assay][data[\"split\"]==1].values.reshape(-1,1)\n",
    "Y_test = data[assay][data[\"split\"]==0].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = set(\"\".join(list(data.smiles))+\"!E\")\n",
    "char_to_int = dict((c,i) for i,c in enumerate(charset))\n",
    "int_to_char = dict((i,c) for i,c in enumerate(charset))\n",
    "embed = max([len(smile) for smile in data.smiles]) + 5\n",
    "print (str(charset))\n",
    "print(len(charset), embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'S', 'P', '#', 'E', '+', '!', '[', 'I', '(', '2', '-', 'F', '/', 'B', 'r', '\\\\', 'O', '3', 'H', ']', ')', 'N', '4', 'C', '=', '1', 'l'}\n",
    "char_to_int \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(smiles):\n",
    "        one_hot =  np.zeros((smiles.shape[0], embed , len(charset)),dtype=np.int8)\n",
    "        for i,smile in enumerate(smiles):\n",
    "            #encode the startchar\n",
    "            one_hot[i,0,char_to_int[\"!\"]] = 1\n",
    "            #encode the rest of the chars\n",
    "            for j,c in enumerate(smile):\n",
    "                one_hot[i,j+1,char_to_int[c]] = 1\n",
    "            #Encode endchar\n",
    "            one_hot[i,len(smile)+1:,char_to_int[\"E\"]] = 1\n",
    "        #Return two, one for input and the other for output\n",
    "            \n",
    "        return one_hot[:,0:-1,:], one_hot[:,1:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _ = vectorize(X_train_smiles)\n",
    "X_test, _ = vectorize(X_test_smiles)\n",
    " \n",
    "\n",
    "X_train[8].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_str_train=[]\n",
    "mol_str_test=[]\n",
    "for x in range(1434):\n",
    " \n",
    "    mol_str_train.append(\"\".join([int_to_char[idx] for idx in np.argmax(X_train[x,:,:], axis=1)]))\n",
    "    \n",
    "    \n",
    "for x in range(358):\n",
    "    mol_str_test.append(\"\".join([int_to_char[idx] for idx in np.argmax(X_test[x,:,:], axis=1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(charset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=embed-1))\n",
    "model.add(keras.layers.Conv1D(192,10,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(keras.layers.Conv1D(192,5,activation='relu'))\n",
    "model.add(keras.layers.Conv1D(192,3,activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    " \n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_str_train = np.asarray(mol_str_train)\n",
    "mol_str_test = np.asarray(mol_str_test)\n",
    " \n",
    "optimizer = Adam(lr=0.00025)\n",
    "lr_metric = get_lr_metric(optimizer)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[coeff_determination, lr_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-15, verbose=1, mode='auto',cooldown=0),\n",
    "    ModelCheckpoint(filepath=\"weights.best.hdf5\", monitor='val_loss', save_best_only=True, verbose=1, mode='auto')\n",
    "    \n",
    "]\n",
    " \n",
    " \n",
    " \n",
    "history =model.fit(x=np.argmax(X_train, axis=2), y=Y_train,\n",
    "                              batch_size=128,\n",
    "                              epochs=150,\n",
    "                              validation_data=(np.argmax(X_test, axis=2),Y_test),\n",
    "                              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    " \n",
    "plt.figure(figsize=(10, 8))\n",
    " \n",
    "for label in ['val_coeff_determination','coeff_determination']:\n",
    "    plt.subplot(221)\n",
    "    plt.plot(hist[label], label = label)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"coeff_determination\")\n",
    "    \n",
    "for label in ['val_loss','loss']:\n",
    "    plt.subplot(222)\n",
    "    plt.plot(hist[label], label = label)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    " \n",
    " \n",
    " \n",
    "plt.subplot(223)\n",
    "plt.plot( hist['lr'],hist['val_coeff_determination']  )\n",
    "plt.legend()\n",
    "plt.xlabel(\"lr\")\n",
    "plt.ylabel(\"val_coeff_determination\")\n",
    " \n",
    " \n",
    "plt.subplot(224)\n",
    "plt.plot( hist['lr'],hist['val_loss']  )\n",
    "plt.legend()\n",
    "plt.xlabel(\"lr\")\n",
    "plt.ylabel(\"val_loss\")\n",
    " \n",
    "    \n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                    wspace=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
